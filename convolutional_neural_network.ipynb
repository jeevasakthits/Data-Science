{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "convolutional_neural_network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJJOqFUGm7z1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"from tensorflow.contrib.keras.api.keras.layers import Dropout\n",
        "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
        "from tensorflow.contrib.keras.api.keras.layers import Conv2D\n",
        "from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D\n",
        "from tensorflow.contrib.keras.api.keras.layers import Flatten\n",
        "from tensorflow.contrib.keras.api.keras.layers import Dense\n",
        "from tensorflow.contrib.keras.api.keras.callbacks import Callback\n",
        "from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.contrib.keras import backend\n",
        "import os\"\"\"\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Convolution2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0E02-_WnNLB",
        "colab_type": "code",
        "outputId": "829368a6-c577-4bd1-9f01-9711cd1db777",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        }
      },
      "source": [
        "\n",
        "#initializing convolutional neural network\n",
        "classifier = Sequential()\n",
        "\n",
        "#step-1 first convolution layer\n",
        "classifier.add(Convolution2D(32,3,3,input_shape=(64,64,3),activation='relu'))\n",
        "\n",
        "#step-2 Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#step-3 convolution  layer\n",
        "classifier.add(Convolution2D(32,3,3,activation='relu'))\n",
        "\n",
        "#step-4 Pooling\n",
        "classifier.add(MaxPooling2D(pool_size = (2,2)))\n",
        "\n",
        "#step-5 Flattening\n",
        "classifier.add(Flatten())\n",
        "\n",
        "#step-4 Fully connection\n",
        "classifier.add(Dense(output_dim= 128,activation='relu'))\n",
        "classifier.add(Dense(output_dim= 1,activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(64, 64, 3..., activation=\"relu\")`\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"relu\", units=128)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"sigmoid\", units=1)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyGSowW9nQC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Cimpiling th CNN\n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piESRhDVG5qQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get_ipython().system_raw(\"unrar x training_set.rar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1K0pCAxdHaEI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#get_ipython().system_raw(\"unrar x test_set.rar\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXuBWLLdnTQS",
        "colab_type": "code",
        "outputId": "d17285c8-4aa3-4b5a-ed39-aa2e210122c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "source": [
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rescale=1./255,\n",
        "        shear_range=0.2,\n",
        "        zoom_range=0.2,\n",
        "        horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(\n",
        "        'training_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "        'test_set',\n",
        "        target_size=(64, 64),\n",
        "        batch_size=32,\n",
        "        class_mode='binary')\n",
        "\n",
        "classifier.fit_generator(\n",
        "        training_set,\n",
        "        steps_per_epoch=8000,\n",
        "        epochs=25,\n",
        "        validation_data=test_set,\n",
        "        validation_steps=2000)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 8000 images belonging to 2 classes.\n",
            "Found 2000 images belonging to 2 classes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/25\n",
            "6190/8000 [======================>.......] - ETA: 9:03 - loss: 0.4162 - acc: 0.7964"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqae2FGBnYfn",
        "colab_type": "code",
        "outputId": "2d84c767-740d-40bb-c327-ed1a13dfe6d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        }
      },
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-dc4b149cac1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m150\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         class_mode='binary')\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m validation_generator = test_datagen.flow_from_directory(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation)\u001b[0m\n\u001b[1;32m    536\u001b[0m             \u001b[0mfollow_links\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfollow_links\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m             \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 538\u001b[0;31m             \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    539\u001b[0m         )\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/directory_iterator.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, dtype)\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m                     \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBtFToiVncNP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compiling the CNN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qVtrGT1rnekZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory(training_set_path,\n",
        "                                                 target_size=input_size,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='binary')\n",
        "\n",
        "test_set = test_datagen.flow_from_directory(test_set_path,\n",
        "                                            target_size=input_size,\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode='binary')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcpngHOfng6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Create a loss history\n",
        "history = LossHistory()\n",
        "\n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=8000/batch_size,\n",
        "                         epochs=90,\n",
        "                         validation_data=test_set,\n",
        "                         validation_steps=2000/batch_size,\n",
        "                         workers=12,\n",
        "                         max_q_size=100,\n",
        "                         callbacks=[history])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGQEs4KEnioY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "# Save model\n",
        "model_backup_path = os.path.join(script_dir, '../dataset/cat_or_dogs_model.h5')\n",
        "classifier.save(model_backup_path)\n",
        "print(\"Model saved to\", model_backup_path)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wp872ee8nkKQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save loss history to file\n",
        "loss_history_path = os.path.join(script_dir, '../loss_history.log')\n",
        "myFile = open(loss_history_path, 'w+')\n",
        "myFile.write(history.losses)\n",
        "myFile.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWik0fETnlXA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "backend.clear_session()\n",
        "print(\"The model class indices are:\", training_set.class_indices)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}