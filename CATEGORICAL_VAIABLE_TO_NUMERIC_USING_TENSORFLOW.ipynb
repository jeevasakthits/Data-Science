{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CATEGORICAL_VAIABLE_TO_NUMERIC_USING_TENSORFLOW.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZuAQQUopVYx",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec\n",
        "here I implement word2vec with very simple example using tensorflow  \n",
        "word2vec is vector representation for words with similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_V65z4FpVYz",
        "colab_type": "text"
      },
      "source": [
        "# Collect Data\n",
        "we will use only 10 sentences to create word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aivFuOq4dSTp",
        "colab_type": "code",
        "outputId": "729cb692-1a15-4193-815d-731101ea5571",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "!pip install kmodes"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting kmodes\n",
            "  Downloading https://files.pythonhosted.org/packages/79/c0/f7d8a0eb41ac6f302b4bc100f91b6e0f2558425ccfefaa0ec0430f77ee97/kmodes-0.10.1-py2.py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.6/dist-packages (from kmodes) (1.16.4)\n",
            "Requirement already satisfied: scikit-learn>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from kmodes) (0.21.2)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.6/dist-packages (from kmodes) (1.3.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from kmodes) (0.13.2)\n",
            "Installing collected packages: kmodes\n",
            "Successfully installed kmodes-0.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryr3P2cCdRh8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from kmodes.kmodes import KModes\n",
        "\n",
        "# random categorical data\n",
        "data = np.random.choice(20, (100, 10))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vr9Ouxlodb0S",
        "colab_type": "code",
        "outputId": "f786c029-d346-4d4e-9a37-9b2029660e5d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1751
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  2, 11,  7, 14, 19,  4,  1,  2, 17],\n",
              "       [ 8,  2,  7,  6, 15,  7,  2, 14,  1, 11],\n",
              "       [11,  8, 16, 12,  9,  2,  6,  1,  1,  2],\n",
              "       [13, 18,  3,  3, 18,  1,  0, 19, 14,  8],\n",
              "       [12,  0, 18,  0, 10, 10, 15,  7, 15, 16],\n",
              "       [18, 16,  8,  7,  9, 12,  9, 11, 18, 17],\n",
              "       [ 5, 14, 11,  7,  8,  5,  2,  4, 17,  5],\n",
              "       [ 5,  8,  9, 19, 19,  3,  5,  8, 18,  0],\n",
              "       [ 7,  0,  8,  2,  8, 17,  5, 17, 14, 14],\n",
              "       [15,  3,  0,  2,  7,  4, 12, 15, 17, 19],\n",
              "       [16,  3, 10,  0, 14,  9,  8, 18, 12,  1],\n",
              "       [ 3,  6, 18, 10, 10,  5,  4, 16,  8, 11],\n",
              "       [17, 10,  0, 16, 18,  8, 13, 17, 16,  1],\n",
              "       [ 9, 11, 11, 11, 19,  8, 10, 14, 16,  7],\n",
              "       [14, 15, 19, 19, 17,  2, 16,  9,  6,  6],\n",
              "       [ 0, 10,  1, 17,  1, 18, 16, 17,  7,  9],\n",
              "       [ 5, 12, 10,  1,  1,  5, 12,  3,  6, 11],\n",
              "       [ 1, 18,  3, 12, 18, 17, 16, 10, 13,  4],\n",
              "       [11, 18, 15,  5,  2,  3, 13,  6, 11, 12],\n",
              "       [ 1,  1, 12,  8,  4,  6, 14, 15, 12,  2],\n",
              "       [ 3, 16,  2, 17,  4, 19, 17,  4, 13, 17],\n",
              "       [ 0, 16, 15,  0,  4, 11,  2,  8,  5, 16],\n",
              "       [14,  3, 19,  1, 11,  0, 12, 18, 18,  4],\n",
              "       [ 7, 14, 19, 11,  9, 17,  8,  5,  2, 18],\n",
              "       [ 9,  7,  4, 10, 14,  8, 15, 15,  4,  2],\n",
              "       [15, 15, 11, 15, 17,  3,  1, 12, 13, 10],\n",
              "       [15,  5, 14, 13, 17, 16, 18,  4, 10, 17],\n",
              "       [13,  8,  4,  8, 12, 18, 15, 10, 14,  8],\n",
              "       [12,  7, 17,  8,  3, 17, 13,  2, 19,  4],\n",
              "       [13, 18, 10,  7,  6, 15, 15,  7,  1,  1],\n",
              "       [ 8,  5,  1,  1,  8, 12,  8,  0, 11, 17],\n",
              "       [ 7,  0, 19,  3, 12, 16,  6,  7,  3,  3],\n",
              "       [ 0, 18, 13,  3, 19,  6,  0,  0, 10,  6],\n",
              "       [ 5, 14, 13, 18,  6, 18, 13,  1,  6,  8],\n",
              "       [ 8, 12,  4, 12, 12,  5, 19, 17, 16, 14],\n",
              "       [ 9, 18,  1,  0,  0, 16, 13,  8, 16, 10],\n",
              "       [ 9,  3,  5,  1, 17,  4, 12, 11, 15, 14],\n",
              "       [18,  1, 19, 17,  0, 10,  6, 16, 12,  1],\n",
              "       [10,  7,  1, 19, 15,  0, 19,  8,  3,  5],\n",
              "       [ 2, 16, 13,  4, 19,  8, 18, 15, 11,  7],\n",
              "       [14, 11, 16, 11,  1,  0,  7,  9,  0,  0],\n",
              "       [ 1, 10,  9,  7,  9,  6, 11,  3, 17,  6],\n",
              "       [16,  6, 11, 12, 17,  2, 14,  6,  6, 15],\n",
              "       [ 1,  1,  3, 10,  7,  1,  4,  7,  4,  5],\n",
              "       [ 3,  3, 17,  5,  4,  9, 11, 15,  3, 13],\n",
              "       [ 6, 15, 10,  2, 19, 15, 17,  5,  1,  0],\n",
              "       [ 5,  7,  3, 11, 12,  0,  0,  6,  9, 13],\n",
              "       [16,  5, 18, 18, 14, 19, 19,  7,  6, 10],\n",
              "       [11,  9,  9, 19,  7,  7, 19, 19,  1,  2],\n",
              "       [15, 16, 11, 19,  4,  2, 13, 17, 14,  5],\n",
              "       [12,  2,  9, 11, 13,  9, 16, 11,  6,  1],\n",
              "       [12,  9, 11, 14,  2, 18,  3,  6, 18, 13],\n",
              "       [ 9,  3,  4,  5,  3, 19,  6,  9, 11, 12],\n",
              "       [ 4, 11,  0, 16, 19, 15,  1, 18,  3,  6],\n",
              "       [ 0, 18,  1, 15, 19,  1,  4, 15,  6, 13],\n",
              "       [ 9, 14,  3,  8, 18,  0, 14,  7, 17,  2],\n",
              "       [18, 17,  1, 17,  4, 10, 14, 10, 11, 11],\n",
              "       [16, 19,  1,  3, 17,  7,  5,  6,  6,  5],\n",
              "       [ 4, 12, 11,  6,  4, 10, 18,  7, 14,  0],\n",
              "       [14,  7, 15, 16,  0, 10, 12,  3,  1, 16],\n",
              "       [ 7, 12, 14, 18, 13, 11,  1,  4,  6,  7],\n",
              "       [ 4,  7, 12, 11, 16, 10, 19, 12,  5,  2],\n",
              "       [12,  8, 12, 18, 13,  3, 19,  3, 13, 13],\n",
              "       [11,  0,  0, 11, 13,  1, 14,  4, 11,  4],\n",
              "       [ 9, 17, 16, 15, 14,  7, 17,  7, 19, 17],\n",
              "       [ 9, 11,  3,  4, 15, 12,  9, 15,  1,  7],\n",
              "       [16,  1, 15,  4, 17, 17,  7,  4, 10,  0],\n",
              "       [19, 13,  8, 19,  2,  7,  9,  2,  6,  2],\n",
              "       [ 3,  8,  7,  3,  5,  7,  5, 10,  2,  4],\n",
              "       [16,  0, 11, 17, 14,  7, 10, 14, 17, 10],\n",
              "       [11,  2, 11, 13, 11,  6, 10, 10, 11,  9],\n",
              "       [ 4, 12,  4, 16, 18, 17, 19,  3,  1, 16],\n",
              "       [ 7,  2,  7, 10, 19, 17, 15,  5, 13,  2],\n",
              "       [14,  1,  6, 11,  3, 11,  2, 15, 18, 12],\n",
              "       [ 1, 15, 19, 11,  2,  2,  7, 14, 18,  8],\n",
              "       [10, 15, 15, 17,  2,  0,  7, 14,  3,  9],\n",
              "       [ 7,  3,  1,  6,  0,  6, 16, 14, 18, 10],\n",
              "       [14, 10, 10, 15,  4,  8, 15, 19,  2,  2],\n",
              "       [17, 16,  8,  2,  5,  2, 18, 15,  5, 12],\n",
              "       [ 2,  0,  3,  7,  8, 16, 18, 14, 18,  8],\n",
              "       [ 1,  9,  6,  2,  8,  2,  1, 18,  8, 19],\n",
              "       [12, 16,  1,  8,  0,  5, 11, 15, 14, 11],\n",
              "       [ 1,  3,  4,  8, 16,  1,  2, 18, 11, 14],\n",
              "       [ 7,  7,  6,  6,  4,  5,  2,  9,  3, 17],\n",
              "       [14, 16, 16, 10,  8,  8,  5, 19,  1, 15],\n",
              "       [ 3,  8,  2, 12, 18, 16, 11,  8, 17,  9],\n",
              "       [11,  8, 16, 13, 17, 13, 18, 17,  1, 14],\n",
              "       [ 3,  8, 19,  0, 12, 15, 14, 11, 10,  6],\n",
              "       [ 4, 16,  7, 15, 18, 14,  4, 13,  7, 11],\n",
              "       [10,  8,  2, 17,  4, 11,  2,  6,  0, 11],\n",
              "       [14,  4,  5,  5, 15, 10, 14, 10, 17,  2],\n",
              "       [10, 10, 17, 11,  0,  2,  0,  5, 18,  0],\n",
              "       [19, 12,  4,  3, 16, 10, 17, 16,  0,  7],\n",
              "       [ 1,  4,  3, 14,  4,  4, 15,  1, 19,  3],\n",
              "       [ 6,  2, 13, 14,  5, 12, 16, 14,  2,  1],\n",
              "       [ 5,  7, 16, 17,  2,  2, 11, 10,  1,  2],\n",
              "       [ 7, 18,  2, 12,  9, 16,  5, 17,  7,  4],\n",
              "       [ 4, 13,  0,  5,  0,  3,  9, 10,  8,  3],\n",
              "       [14, 19, 15, 18,  9, 11,  1,  5,  6,  0],\n",
              "       [10,  1, 11, 16, 13,  4, 19,  0,  8, 16]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNaXwjZ0dawx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from kmodes.kmodes import KModes\n",
        "km = KModes(n_clusters=4, init='Huang', n_init=5, verbose=1)\n",
        "\n",
        "clusters = km.fit_predict(data)\n",
        "\n",
        "# Print the cluster centroids\n",
        "print(km.cluster_centroids_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9oAF71wpVYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = ['king is a strong man', \n",
        "          'queen is a wise woman', \n",
        "          'boy is a young man',\n",
        "          'girl is a young woman',\n",
        "          'prince is a young king',\n",
        "          'princess is a young queen',\n",
        "          'man is strong', \n",
        "          'woman is pretty',\n",
        "          'prince is a boy will be king',\n",
        "          'princess is a girl will be queen']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0qQuMSuXpVY3",
        "colab_type": "text"
      },
      "source": [
        "# Remove stop words\n",
        "In order for efficiency of creating word vector, we will remove commonly used words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFvVXEnZpVY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def remove_stop_words(corpus):\n",
        "    stop_words = ['is', 'a', 'will', 'be']\n",
        "    results = []\n",
        "    for text in corpus:\n",
        "        tmp = text.split(' ')\n",
        "        for stop_word in stop_words:\n",
        "            if stop_word in tmp:\n",
        "                tmp.remove(stop_word)\n",
        "        results.append(\" \".join(tmp))\n",
        "    \n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHngYT4gpVY6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "corpus = remove_stop_words(corpus)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wcJWWMOYuryN",
        "colab_type": "code",
        "outputId": "38e778d7-c894-4d22-a785-87e3cd4e41bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "corpus"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['king strong man',\n",
              " 'queen wise woman',\n",
              " 'boy young man',\n",
              " 'girl young woman',\n",
              " 'prince young king',\n",
              " 'princess young queen',\n",
              " 'man strong',\n",
              " 'woman pretty',\n",
              " 'prince boy king',\n",
              " 'princess girl queen']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hx5CUQAypVY9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "words = []\n",
        "for text in corpus:\n",
        "    for word in text.split(' '):\n",
        "        words.append(word)\n",
        "\n",
        "words = set(words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLGC4bfXpVY_",
        "colab_type": "text"
      },
      "source": [
        "here we have word set by which we will have word vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SI84eCApVY_",
        "colab_type": "code",
        "outputId": "d7200b6b-3a3d-4c57-fda5-798a93bd411b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy',\n",
              " 'girl',\n",
              " 'king',\n",
              " 'man',\n",
              " 'pretty',\n",
              " 'prince',\n",
              " 'princess',\n",
              " 'queen',\n",
              " 'strong',\n",
              " 'wise',\n",
              " 'woman',\n",
              " 'young'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cFwZ8Si2pVZE",
        "colab_type": "text"
      },
      "source": [
        "# data generation\n",
        "we will generate label for each word using skip gram.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTnGOb-lpVZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2int = {}\n",
        "\n",
        "for i,word in enumerate(words):\n",
        "    word2int[word] = i\n",
        "\n",
        "sentences = []\n",
        "for sentence in corpus:\n",
        "    sentences.append(sentence.split())\n",
        "    \n",
        "WINDOW_SIZE = 2\n",
        "\n",
        "data = []\n",
        "for sentence in sentences:\n",
        "    for idx, word in enumerate(sentence):\n",
        "        for neighbor in sentence[max(idx - WINDOW_SIZE, 0) : min(idx + WINDOW_SIZE, len(sentence)) + 1] : \n",
        "            if neighbor != word:\n",
        "                data.append([word, neighbor])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7oxg5PKgu6Jg",
        "colab_type": "code",
        "outputId": "8c32d027-9eca-4ff0-e160-aab8f9d09b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 901
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['king', 'strong'],\n",
              " ['king', 'man'],\n",
              " ['strong', 'king'],\n",
              " ['strong', 'man'],\n",
              " ['man', 'king'],\n",
              " ['man', 'strong'],\n",
              " ['queen', 'wise'],\n",
              " ['queen', 'woman'],\n",
              " ['wise', 'queen'],\n",
              " ['wise', 'woman'],\n",
              " ['woman', 'queen'],\n",
              " ['woman', 'wise'],\n",
              " ['boy', 'young'],\n",
              " ['boy', 'man'],\n",
              " ['young', 'boy'],\n",
              " ['young', 'man'],\n",
              " ['man', 'boy'],\n",
              " ['man', 'young'],\n",
              " ['girl', 'young'],\n",
              " ['girl', 'woman'],\n",
              " ['young', 'girl'],\n",
              " ['young', 'woman'],\n",
              " ['woman', 'girl'],\n",
              " ['woman', 'young'],\n",
              " ['prince', 'young'],\n",
              " ['prince', 'king'],\n",
              " ['young', 'prince'],\n",
              " ['young', 'king'],\n",
              " ['king', 'prince'],\n",
              " ['king', 'young'],\n",
              " ['princess', 'young'],\n",
              " ['princess', 'queen'],\n",
              " ['young', 'princess'],\n",
              " ['young', 'queen'],\n",
              " ['queen', 'princess'],\n",
              " ['queen', 'young'],\n",
              " ['man', 'strong'],\n",
              " ['strong', 'man'],\n",
              " ['woman', 'pretty'],\n",
              " ['pretty', 'woman'],\n",
              " ['prince', 'boy'],\n",
              " ['prince', 'king'],\n",
              " ['boy', 'prince'],\n",
              " ['boy', 'king'],\n",
              " ['king', 'prince'],\n",
              " ['king', 'boy'],\n",
              " ['princess', 'girl'],\n",
              " ['princess', 'queen'],\n",
              " ['girl', 'princess'],\n",
              " ['girl', 'queen'],\n",
              " ['queen', 'princess'],\n",
              " ['queen', 'girl']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EBuPOkxpVZH",
        "colab_type": "code",
        "outputId": "28fc1da6-79ea-41a2-ec0d-14bf0a0cc5bb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import pandas as pd\n",
        "for text in corpus:\n",
        "    print(text)\n",
        "\n",
        "df = pd.DataFrame(data, columns = ['input', 'label'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "king strong man\n",
            "queen wise woman\n",
            "boy young man\n",
            "girl young woman\n",
            "prince young king\n",
            "princess young queen\n",
            "man strong\n",
            "woman pretty\n",
            "prince boy king\n",
            "princess girl queen\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMACqYGIpVZL",
        "colab_type": "code",
        "outputId": "89f07c0f-80e8-4342-9020-814126156d5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>king</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>king</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>strong</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strong</td>\n",
              "      <td>man</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>man</td>\n",
              "      <td>king</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>man</td>\n",
              "      <td>strong</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>queen</td>\n",
              "      <td>wise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>queen</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>wise</td>\n",
              "      <td>queen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>wise</td>\n",
              "      <td>woman</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    input   label\n",
              "0    king  strong\n",
              "1    king     man\n",
              "2  strong    king\n",
              "3  strong     man\n",
              "4     man    king\n",
              "5     man  strong\n",
              "6   queen    wise\n",
              "7   queen   woman\n",
              "8    wise   queen\n",
              "9    wise   woman"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kukfx9fpVZO",
        "colab_type": "code",
        "outputId": "0fe31bab-0ddf-43f7-c52c-519f14954af6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(52, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOk27FZnpVZR",
        "colab_type": "code",
        "outputId": "4befea7e-f40c-4e02-e785-39b185fec599",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "word2int"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'boy': 0,\n",
              " 'girl': 7,\n",
              " 'king': 1,\n",
              " 'man': 10,\n",
              " 'pretty': 5,\n",
              " 'prince': 4,\n",
              " 'princess': 8,\n",
              " 'queen': 11,\n",
              " 'strong': 3,\n",
              " 'wise': 2,\n",
              " 'woman': 6,\n",
              " 'young': 9}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDFqb5HIpVZU",
        "colab_type": "text"
      },
      "source": [
        "# Define Tensorflow Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn7xB23QpVZV",
        "colab_type": "code",
        "outputId": "2d70e092-cc58-4ba6-b876-feb969f38f8b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "ONE_HOT_DIM = len(words)\n",
        "\n",
        "# function to convert numbers to one hot vectors\n",
        "def to_one_hot_encoding(data_point_index):\n",
        "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
        "    one_hot_encoding[data_point_index] = 1\n",
        "    return one_hot_encoding\n",
        "\n",
        "X = [] # input word\n",
        "Y = [] # target word\n",
        "\n",
        "for x, y in zip(df['input'], df['label']):\n",
        "    X.append(to_one_hot_encoding(word2int[ x ]))\n",
        "    Y.append(to_one_hot_encoding(word2int[ y ]))\n",
        "\n",
        "# convert them to numpy arrays\n",
        "X_train = np.asarray(X)\n",
        "Y_train = np.asarray(Y)\n",
        "\n",
        "# making placeholders for X_train and Y_train\n",
        "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
        "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
        "\n",
        "# word embedding will be 2 dimension for 2d visualization\n",
        "EMBEDDING_DIM = 2 \n",
        "\n",
        "# hidden layer: which represents word vector eventually\n",
        "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
        "b1 = tf.Variable(tf.random_normal([1])) #bias\n",
        "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
        "\n",
        "# output layer\n",
        "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
        "b2 = tf.Variable(tf.random_normal([1]))\n",
        "prediction = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
        "\n",
        "# loss function: cross entropy\n",
        "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(prediction), axis=[1]))\n",
        "\n",
        "# training operation\n",
        "train_op = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4VJxcrAVpVZY",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYTCib7PpVZY",
        "colab_type": "code",
        "outputId": "e167475a-8eb9-425c-8263-caa148c2e713",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init) \n",
        "\n",
        "iteration = 20000\n",
        "for i in range(iteration):\n",
        "    # input is X_train which is one hot encoded word\n",
        "    # label is Y_train which is one hot encoded neighbor word\n",
        "    sess.run(train_op, feed_dict={x: X_train, y_label: Y_train})\n",
        "    if i % 3000 == 0:\n",
        "        print('iteration '+str(i)+' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iteration 0 loss is :  4.4635706\n",
            "iteration 3000 loss is :  1.862313\n",
            "iteration 6000 loss is :  1.7775974\n",
            "iteration 9000 loss is :  1.7451575\n",
            "iteration 12000 loss is :  1.7261015\n",
            "iteration 15000 loss is :  1.7097957\n",
            "iteration 18000 loss is :  1.6930954\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x8pm1a6pVZe",
        "colab_type": "code",
        "outputId": "6bc9f804-4f45-44af-8d83-7b4c566352dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# Now the hidden layer (W1 + b1) is actually the word look up table\n",
        "vectors = sess.run(W1 + b1)\n",
        "print(vectors)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.9985096  -0.08295059]\n",
            " [-1.2697171  -0.10487342]\n",
            " [ 2.4785545  -2.1502647 ]\n",
            " [-3.868463    2.7949507 ]\n",
            " [-4.2329655  -0.41116747]\n",
            " [ 3.855162   -0.7234088 ]\n",
            " [ 0.2097857  -1.0648084 ]\n",
            " [ 1.5419219  -4.061035  ]\n",
            " [ 1.7330186  -4.7841372 ]\n",
            " [ 0.31198376  0.5024212 ]\n",
            " [-2.981151   -0.48963925]\n",
            " [ 0.53641576 -1.5084531 ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8VHBGtIpVZh",
        "colab_type": "text"
      },
      "source": [
        "# word vector in table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FGRgIElpVZi",
        "colab_type": "code",
        "outputId": "d67c26ed-71c5-4356-f434-fcacee46da9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
        "w2v_df['word'] = words\n",
        "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
        "w2v_df"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>x1</th>\n",
              "      <th>x2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>boy</td>\n",
              "      <td>-1.998510</td>\n",
              "      <td>-0.082951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>king</td>\n",
              "      <td>-1.269717</td>\n",
              "      <td>-0.104873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wise</td>\n",
              "      <td>2.478554</td>\n",
              "      <td>-2.150265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>strong</td>\n",
              "      <td>-3.868463</td>\n",
              "      <td>2.794951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>prince</td>\n",
              "      <td>-4.232965</td>\n",
              "      <td>-0.411167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>pretty</td>\n",
              "      <td>3.855162</td>\n",
              "      <td>-0.723409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>woman</td>\n",
              "      <td>0.209786</td>\n",
              "      <td>-1.064808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>girl</td>\n",
              "      <td>1.541922</td>\n",
              "      <td>-4.061035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>princess</td>\n",
              "      <td>1.733019</td>\n",
              "      <td>-4.784137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>young</td>\n",
              "      <td>0.311984</td>\n",
              "      <td>0.502421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>man</td>\n",
              "      <td>-2.981151</td>\n",
              "      <td>-0.489639</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>queen</td>\n",
              "      <td>0.536416</td>\n",
              "      <td>-1.508453</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        word        x1        x2\n",
              "0        boy -1.998510 -0.082951\n",
              "1       king -1.269717 -0.104873\n",
              "2       wise  2.478554 -2.150265\n",
              "3     strong -3.868463  2.794951\n",
              "4     prince -4.232965 -0.411167\n",
              "5     pretty  3.855162 -0.723409\n",
              "6      woman  0.209786 -1.064808\n",
              "7       girl  1.541922 -4.061035\n",
              "8   princess  1.733019 -4.784137\n",
              "9      young  0.311984  0.502421\n",
              "10       man -2.981151 -0.489639\n",
              "11     queen  0.536416 -1.508453"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k9F-sUcfpVZm",
        "colab_type": "text"
      },
      "source": [
        "# word vector in 2d chart"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdWl6qWNpVZn",
        "colab_type": "code",
        "outputId": "f7bcd739-ed53-4e59-8e33-4c0c62522371",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
        "    ax.annotate(word, (x1,x2 ))\n",
        "    \n",
        "PADDING = 1.0\n",
        "x_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
        "y_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
        "x_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
        "y_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
        " \n",
        "plt.xlim(x_axis_min,x_axis_max)\n",
        "plt.ylim(y_axis_min,y_axis_max)\n",
        "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAHupJREFUeJzt3XtwVdXd//H3IgEyXAwMRBRBEmcA\nITm5g4YQrkWiRClKhDzQASJaEbUyGqmVB6RgpxSK1hawKBoELwhUioqYBLAkGEouJHIxXNRIK7Ym\n/UUkIDyErN8fgVORQEJyyEl2Pq8ZZzznrLPWd+86n67ss/baxlqLiIg4RwtvFyAiIp6lYBcRcRgF\nu4iIwyjYRUQcRsEuIuIwCnYREYdRsIuIOIyCXUTEYRTsIiIO4+uNQTt37mwDAwO9MbSISJOVl5dX\naq0NqKmdV4I9MDCQ3NxcbwwtItJkGWO+rE07XYoREXEYBbuIiMMo2EVEHEbBLiLiMAp2ERGHUbCL\niDiMgl1ExGEU7CIiDqNgFxFxGAW7iIjDKNhFRBxGwS4i4jAKdhERh1Gw19Pzzz/PyZMnvV2GiIib\ngr2eLhfsZ8+ebeBqREQU7FfkxIkTjBo1irCwMEJCQpg7dy5Hjx5l6NChDB06FIB27drx+OOPExYW\nRnZ2Nlu2bCEiIgKXy0VycjKnT58GqvaknzNnDpGRkbhcLoqKigAoKSlhxIgRBAcHM3XqVHr06EFp\naanXjllEmh4F+xXYvHkzXbt2pbCwkL179/LYY4/RtWtXtm3bxrZt24Cq8L/lllsoLCwkOjqayZMn\ns2bNGvbs2UNFRQXLli1z99e5c2fy8/OZNm0aixYtAmDu3LkMGzaMffv2MXbsWI4cOeKVYxWRpkvB\nfgVcLhfp6enMnDmTzMxM/P39L2rj4+PDPffcA8CBAwcICgqiV69eAEyaNInt27e72959990AREVF\nUVxcDEBWVhbjx48HID4+no4dO17NQxIRB/LKo/Gaql69epGfn8+mTZuYNWsWw4cPv6iNn58fPj4+\nteqvdevWQNX/GVRUVHi0VhFpvjRjvwJHjx6lTZs2TJw4kZSUFPLz82nfvj3Hjx+vtn3v3r0pLi7m\n8OHDAKxatYrBgwdfdozY2FjefvttANLS0igrK/PsQYiI42nGfgX27NlDSkoKLVq0oGXLlixbtozs\n7Gzi4+Pd19p/yM/Pj1dffZXExEQqKiro168fDz744GXHmDNnDklJSaxatYqYmBiuu+462rdvfzUP\nS0QcxlhrG3zQ6Ohom5ub2+DjNgWnT5/Gx8cHX19fsrOzmTZtGgUFBd4uS0QaAWNMnrU2uqZ2mrE3\nMkeOHOHee++lsrKSVq1a8dJLL3m7JBFpYhTsjUzPnj3ZvXu3t8sQkSZMP56KiDiMgl1ExGEU7CIi\nDqNgFxFxGAW7iIjDKNhFRBxGwS4i4jAKdhERh1Gwi4g4jIJdRMRhFOwiIg5T72A3xnQ3xmwzxuw3\nxuwzxvzCE4WJiEjdeGITsArgcWttvjGmPZBnjEm31u73QN8iInKF6j1jt9Z+ba3NP/fvx4FPgRvq\n26+IiNSNR6+xG2MCgQjg757sV0REas9jwW6MaQesBx6z1n5XzecPGGNyjTG5JSUlnhpWRER+xCPB\nboxpSVWov26t/Ut1bay1y6210dba6ICAAE8MKyIi1fDEqhgDrAA+tdYurn9JIiJSH56YsccCPwOG\nGWMKzv1zhwf6FRGROqj3ckdrbRZgPFCLiIh4gO48FRFxGAW7iIjDKNhFRBxGwS4i4jAKdhERh1Gw\ni4g4jIJdRMRhFOwiIg6jYBcRcRgFu4iIwyjYRUQcRsEuIuIwCnYREYdRsIuIOIyCXUTEYRTsIiIO\no2AXEXEYBbuIiMMo2EVEHEbBLiLiMAp2ERGHUbCLiDiMgl1ExGEU7CIeNnv2bJ5//nn366effpo/\n/OEPpKSkEBISgsvlYs2aNQB89NFHJCQkuNs+/PDDpKamAhAYGMicOXOIjIzE5XJRVFQEQElJCSNG\njCA4OJipU6fSo0cPSktLG+4ApdFTsIt4WHJyMq+99hoAlZWVvPXWW3Tr1o2CggIKCwvJyMggJSWF\nr7/+usa+OnfuTH5+PtOmTWPRokUAzJ07l2HDhrFv3z7Gjh3LkSNHrurxSNOjYBfxsMDAQDp16sTu\n3btJS0sjIiKCrKwskpKS8PHxoUuXLgwePJicnJwa+7r77rsBiIqKori4GICsrCzGjx8PQHx8PB07\ndrxqxyJNk6+3CxBxoqlTp5Kamsq//vUvkpOTSU9Pr7adr68vlZWV7tenTp264PPWrVsD4OPjQ0VF\nxdUrWBxFM3aRq2DMmDFs3ryZnJwcRo4cSVxcHGvWrOHs2bOUlJSwfft2+vfvT48ePdi/fz+nT5/m\n22+/ZcuWLTX2HRsby9tvvw1AWloaZWVlV/twpInRjF3kKmjVqhVDhw6lQ4cO+Pj4MGbMGLKzswkL\nC8MYw+9+9zuuu+46AO69915CQkIICgoiIiKixr7nzJlDUlISq1atIiYmhuuuu4727dtf7UOSJsRY\naxt80OjoaJubm9vg44o0lMrKSiIjI1m7di09e/b0aN+nT5/Gx8cHX19fsrOzmTZtGgUFBR4dQxon\nY0yetTa6pnaasYt42P79+0lISGDMmDEeD3WAI0eOcO+991JZWUmrVq146aWXPD6GNG2asYuINBG1\nnbHrx1MREYdRsIuIOIyCXUTEYRTsUqPi4mJCQkIatP/c3FweffTRqzamiJNpVYw0StHR0URH1/gb\nkYhUwyMzdmNMvDHmgDHmsDHml57oUxqXiooKJkyYQJ8+fRg7diwnT55ky5YtRERE4HK5SE5O5vTp\n02zdupWf/vSn7u+lp6czZsyYWo/z+eefExERwcKFC927Hj7zzDMkJyczZMgQbrrpJl544QV3+3nz\n5tG7d28GDhxIUlKSe6Mskeas3sFujPEBlgC3A32BJGNM3/r2K43LgQMHeOihh/j000+55pprWLx4\nMZMnT2bNmjXs2bOHiooKli1bxtChQykqKqKkpASAV199leTk5FqPcc8995Camkq/fv0u+KyoqIgP\nP/yQXbt2MXfuXM6cOUNOTg7r16+nsLCQDz74AC2hFaniiRl7f+CwtfZza+3/AW8Boz3QrzQi3bt3\nJzY2FoCJEyeyZcsWgoKC6NWrFwCTJk1i+/btGGP42c9+xurVq/n222/Jzs7m9ttvr7H/kpISRo8e\nzeuvv05YWNhFn48aNYrWrVvTuXNnrr32Wv7973+zY8cORo8ejZ+fH+3bt+fOO+/07EGLNFGeuMZ+\nA/CPH7z+J3CLB/qVRsQYc8HrDh068J///KfatlOmTOHOO+/Ez8+PxMREfH1r/s/M39+fG2+8kays\nLPr2vfgPvvO7HIJ2OhSpSYOtijHGPGCMyTXG5J7/M12ajiNHjpCdnQ3AG2+8QXR0NMXFxRw+fBiA\nVatWMXjwYAC6du1K165dmT9/PlOmTKlV/61ateKdd97htdde44033qjVd2JjY3n33Xc5deoU5eXl\nvPfee3U4MhHn8USwfwV0/8Hrbufeu4C1drm1NtpaGx0QEOCBYRvO7NmzycjI8HYZXtW7d2+WLFlC\nnz59KCsrY8aMGbz66qskJibicrlo0aIFDz74oLv9hAkT6N69O3369Kn1GG3btuW9997jueee47vv\nvquxfb9+/bjrrrsIDQ3l9ttvx+Vy4e/vX6fjE3GSeu8VY4zxBQ4Cw6kK9Bzgf6y1+y71naa0V8zZ\ns2fx8fHxdhlNzsMPP0xERAT33XffVR2nvLycdu3acfLkSQYNGsTy5cuJjIy8qmOKeEuD7RVjra0A\nHgY+BD4F3r5cqDcmxcXF3HzzzRct4wsMDGTmzJnubVcnT57MunXrgEs/YLi8vJwpU6bgcrkIDQ1l\n/fr1QNWDEGJiYoiMjCQxMZHy8nKvHW9DiYqK4pNPPmHixIlXfawHHniA8PBwIiMjueeeexTqInjo\nBiVr7SZgkyf6amgHDhxgxYoVxMbGkpyczNKlSwHo1KkT+fn5AGzevPmC75x/wPDSpUtZtGgRL7/8\nMvPmzcPf3589e/YAUFZWRmlpKfPnzycjI4O2bduyYMECFi9ezOzZsxv2IBtYXl5eg41V2+vxIs1J\ns99S4MfL+LKysgAYN27cJb9T3QOGMzIymD59urtNx44d2blzJ/v37yc2Npbw8HBWrlzJl19+ecU1\nnv/LYvLkyfTq1YsJEyaQkZFBbGwsPXv2ZNeuXezatYuYmBgiIiIYMGAABw4cACA1NZW7776b+Ph4\nevbsyZNPPnnF44tI09LstxT48TK+86/btm17ye/U9gHD1lpGjBjBm2++We86Dx8+zNq1a3nllVfo\n168fb7zxBllZWWzcuJHf/OY3vPbaa2RmZuLr60tGRga/+tWv3JeDCgoK2L17N61bt6Z379488sgj\ndO/evYYRRaSpavYz9h8v4xs4cGCd+hkxYgRLlixxvy4rK+PWW29lx44d7iWBJ06c4ODBg3XqPygo\nyL36JDg4mOHDh2OMweVyUVxczLFjx0hMTCQkJIQZM2awb99/f+YYPnw4/v7++Pn50bdv3zr91SAi\nTUezD/YfL+ObNm1anfqZNWsWZWVlhISEEBYWxrZt2wgICCA1NZWkpCRCQ0OJiYlx/9h6pX54g06L\nFi3cr1u0aEFFRQX/+7//y9ChQ9m7d697bXd139XNPSLesWHDBvbv3+9+nZqaytGjR6/KWM3+Uoyv\nry+rV6++4L3z183PS01Nrfaz6OhoPvroIwDatWvHypUrL+p/2LBh5OTkeKrcSzp27Bg33HADcGG9\nItJwLrc8esOGDSQkJLjvrE5NTSUkJISuXbt6vI5mP2N3iieffJKnnnqKiIgIzchFroLaLo/+7LPP\niI+PJyoqiri4OIqKivj444/ZuHEjKSkphIeHs2DBAnJzc5kwYQLh4eG8//779doV9SLW2gb/Jyoq\nyoqINCVffPGFBWxWVpa11topU6bYhQsX2h49etgFCxa42w0bNswePHjQWmvtzp077dChQ6211k6a\nNMmuXbvW3W7w4ME2JyfHWmttZWWl7d27t/3mm2+stdYmJSXZjRs3XlQDkGtrkbHN/lKMiEht/Xh5\n9PlnA5xfHl1eXs7HH39MYmKi+zunT5+usd8f7oo6ZcoUsrOzee211+pcp4JdRKSWaloeXVlZSYcO\nHSgoKLjivuuyK+ql6Bq7iEgt1bQ8+pprriEoKIi1a9cCVZe6CwsLAWjfvj3Hjx93t/3x67rsinop\nCnYRkVqqzfLo119/nRUrVhAWFkZwcDB//etfARg/fjwLFy4kIiKCzz77jMmTJ/Pggw8SHh7O999/\nD9RtV9Tq1Ht3x7poSrs7iohA1aqYhIQE9u7de9XGqGlX1Nru7qhr7CIijUBUVBRt27bl97//fb37\n0qUYEQ9YuHChe4XEjBkzGDZsGABbt25lwoQJvPnmm7hcLkJCQpg5c6b7e+3atSMlJYXg4GB+8pOf\nsGvXLoYMGcJNN93Exo0bgaqZYlxcHJGRkURGRvLxxx8D8NFHHzFkyBDGjh3rXl/tjb/Am4vAwMCr\nOlvPy8tj+/btF9wpXlcKdhEPiIuLIzMzE4Dc3FzKy8s5c+YMmZmZ9OrVi5kzZ7J161YKCgrIyclh\nw4YNQNX+QcOGDWPfvn20b9+eWbNmkZ6ezjvvvOPe3vnaa68lPT2d/Px81qxZw6OPPuoed/fu3Tz/\n/PPs37+fzz//nB07djT8wUujo2AX8YCoqCjy8vL47rvvaN26NTExMeTm5pKZmUmHDh0YMmQIAQEB\n+Pr6MmHCBLZv3w5UPes1Pj4eAJfLxeDBg2nZsqV7czeAM2fOcP/99+NyuUhMTLxgv5H+/fvTrVs3\nWrRoQXh4+EXbYUjzpGvsIh7QsmVLgoKCSE1NZcCAAYSGhrJt2zYOHz5MYGDgJR8+0rJlS/da6Oo2\ndwN47rnn6NKlC4WFhVRWVuLn5+f+vjZ4k+poxi7iIXFxcSxatIhBgwYRFxfHiy++SEREBP379+dv\nf/sbpaWlnD17ljfffJPBgwfXut9jx45x/fXX06JFC1atWsXZs2ev4lGIEyjYRTwkLi6Or7/+mpiY\nGLp06YKfnx9xcXFcf/31/Pa3v2Xo0KGEhYURFRXF6NGja93vQw89xMqVKwkLC6OoqOiyD4ERAa1j\nFxFpMmq7jl0zdhERh1Gwi4g4jIJdRMRhFOwiXvDss8/Sq1cvBg4cSFJSEosWLWLIkCGc/+2ptLSU\nwMBAoOpxaykpKfTr14/Q0FD+/Oc/u/tZuHCh+/05c+YAVXeq9unTh/vvv5/g4GBuu+029yZT0jwo\n2EUaWF5eHm+99RYFBQVs2rSpxmfirlixAn9/f3JycsjJyeGll17iiy++IC0tjUOHDrFr1y4KCgrc\nt6QDHDp0iOnTp7Nv3z46dOjA+vXrG+LQpJHQDUoiDSwzM5MxY8bQpk0bAO66667Ltk9LS+OTTz5h\n3bp1QNW69kOHDpGWlkZaWhoRERFA1dN7Dh06xI033khQUBDh4eFA1V2xuiO1eVGwizQSvr6+VFZW\nAnDq1Cn3+9Za/vjHPzJy5MgL2n/44Yc89dRT/PznP7/g/eLi4ovuSNWlmOZFl2JEGtigQYPYsGED\n33//PcePH+fdd98FuGDrgfOzc4CRI0eybNkyzpw5A8DBgwc5ceIEI0eO5JVXXqG8vByAr776im++\n+aaBj0YaI83YRRpYZGQk48aNIywsjGuvvZZ+/foB8MQTT3DvvfeyfPlyRo0a5W4/depUiouLiYyM\nxFpLQEAAGzZs4LbbbuPTTz8lJiYGqNoCePXq1fj4+HjluKTx0J2nIl72zDPP0K5dO5544glvlyKN\nnO48FRFppnQpRsTLnnnmGW+XIA6jGbuIiMMo2EVEHEbBLiLiMAp2ERGHqVewG2MWGmOKjDGfGGPe\nMcZ08FRhItI83XHHHXz77bfeLqNJq++MPR0IsdaGAgeBp+pfkog0Z5s2baJDB80R66NewW6tTbPW\nnn8s+k6gW/1LEhEnW7hwIS+88AIAM2bMYNiwYQBs3bqVCRMmEBgYSGlpKSdOnGDUqFGEhYUREhLC\nmjVrgKrdMQcPHkxUVBQjR47k66+/9tqxNFaevMaeDHzgwf5ExIHi4uLIzMwEIDc3l/Lycs6cOUNm\nZiaDBg1yt9u8eTNdu3alsLCQvXv3Eh8fz5kzZ3jkkUdYt24deXl5JCcn8/TTT3vrUBqtGoPdGJNh\njNlbzT+jf9DmaaACeP0y/TxgjMk1xuSWlJR4pnoRaXKioqLIy8vju+++o3Xr1sTExJCbm0tmZiZx\ncXHudi6Xi/T0dGbOnElmZib+/v4cOHCAvXv3MmLECMLDw5k/fz7//Oc/vXg0jVONd55aa39yuc+N\nMZOBBGC4vczGM9ba5cByqNor5srKFBGnaNmyJUFBQaSmpjJgwABCQ0PZtm0bhw8fpk+fPu52vXr1\nIj8/n02bNjFr1iyGDx/OmDFjCA4OJjs724tH0PjVd1VMPPAkcJe19qRnShIRp4uLi2PRokUMGjSI\nuLg4XnzxRSIiIjDGuNscPXqUNm3aMHHiRFJSUsjPz6d3796UlJS4g/3MmTPs27fPW4fRaNV3r5g/\nAa2B9HP/g+y01j5Y76pExNHi4uJ49tlniYmJoW3btvj5+V1wGQZgz549pKSk0KJFC1q2bMmyZcto\n1aoV69at49FHH+XYsWNUVFTw2GOPERwc7KUjaZy0ba+ISBOhbXtFRJopBbuIiMMo2EVEHEbBLiLi\nMAp2ERGHUbCLiDiMgl1ExGEU7CIiDqNgFxFxGAW7iIjDKNhFRBxGwS4i4jAKdhERh1Gwi4g4jIJd\nRMRhFOwiIg6jYBcRcRgFu4iIwyjYRUQcRsEuIuIwCnYREYdRsIuIOIyCXUTEYRTsIiIOo2AXEXEY\nBbuIiMMo2EVEHEbBLiLiMAp2ERGHUbCLiDiMgl1ExGEU7CIiDqNgFxFxGAW7iIjDKNhFxG327Nlk\nZGRU+9nkyZNZt25dA1ckdeHr7QJEpPH49a9/Xe37Z8+ebeBKpD4U7CLN1Lx581i9ejUBAQF0796d\nqKgo9u7dS0JCAmPHjiUwMJBx48aRnp7Ok08+6e1y5Qp45FKMMeZxY4w1xnT2RH8icnXl5OSwfv16\nCgsL+eCDD8jNza22XadOncjPz2f8+PENXKHUR71n7MaY7sBtwJH6lyMiDWHHjh2MHj0aPz8//Pz8\nuPPOO6ttN27cuAauTDzBEzP254AnAeuBvkSkEWnbtq23S5A6qFewG2NGA19Zawtr0fYBY0yuMSa3\npKSkPsOKSD3Fxsby7rvvcurUKcrLy3nvvfe8XZJ4UI2XYowxGcB11Xz0NPArqi7D1MhauxxYDhAd\nHa3ZvYgX9evXj7vuuovQ0FC6dOmCy+XC39/f22WJhxhr65axxhgXsAU4ee6tbsBRoL+19l+X+250\ndLS91I81ItIwysvLadeuHSdPnmTQoEEsX76cyMhIb5cll2GMybPWRtfUrs4/nlpr9wDX/mDAYiDa\nWlta1z5FpOE88MAD7N+/n1OnTjFp0iSFuoNoHbtIM/XGG294uwS5SjwW7NbaQE/1JSIidae9YkRE\nHEbBLiLiMAp2ERGHUbCLiDiMgl1E6uRye7eLd2m5o4hcsbNnz15y73bxPs3YReQCxcXF3HzzzUyY\nMIE+ffowduxYTp48SWBgIDNnziQyMpK1a9de8ESlwMBA5syZQ2RkJC6Xi6KiIqDq7tYpU6bgcrkI\nDQ1l/fr1AKSlpRETE0NkZCSJiYmUl5cD8Mtf/pK+ffsSGhrKE088AcDatWsJCQkhLCyMQYMGeeGM\nND2asYvIRQ4cOMCKFSuIjY0lOTmZpUuXAv/dnx1g8+bNF3ync+fO5Ofns3TpUhYtWsTLL7/MvHnz\n8Pf3Z8+ePQCUlZVRWlrK/PnzycjIoG3btixYsIDFixczffp03nnnHYqKijDG8O233wJVT3X68MMP\nueGGG9zvyeVpxi4iF+nevTuxsbEATJw4kaysLODy+7PffffdAERFRVFcXAxARkYG06dPd7fp2LEj\nO3fuZP/+/cTGxhIeHs7KlSv58ssv8ff3x8/Pj/vuu4+//OUvtGnTBqjaiXLy5Mm89NJLekRfLWnG\nLiIXMcZU+/py+7O3bt0aAB8fHyoqKi7ZzlrLiBEjePPNNy/6bNeuXWzZsoV169bxpz/9ia1bt/Li\niy/y97//nffff5+oqCjy8vLo1KlTXQ6r2dCMXUQucuTIEbKzs4GqPWUGDhxYp35GjBjBkiVL3K/L\nysq49dZb2bFjB4cPHwbgxIkTHDx4kPLyco4dO8Ydd9zBc889R2Fh1WMePvvsM2655RZ+/etfExAQ\nwD/+8Y96Hp3zKdhF5CK9e/dmyZIl9OnTh7KyMqZNm1anfmbNmkVZWZn7x89t27YREBBAamoqSUlJ\nhIaGEhMTQ1FREcePHychIYHQ0FAGDhzI4sWLAUhJScHlchESEsKAAQMICwvz5KE6Up33Y68P7ccu\n0ngVFxeTkJDA3r17vV2K/Eht92PXjF1ExGEU7CJygcDAQM3WmzgFu4iIwyjYRUQcRsEuIuIwCnYR\nEYdRsIuIOIyCXUTEYRTsIiIOo2AXEXEYBbuIiMMo2EVEHEbBLiLiMAp2ERGHUbCLiDiMgl1ExGEU\n7CIiDqNgFxFxGAW7iIjDKNhFRBxGwS4i4jAKdhERhzHW2oYf1JgS4MsGH/jKdAZKvV1EI6Dz8F86\nF1V0Hqp44zz0sNYG1NTIK8HeFBhjcq210d6uw9t0Hv5L56KKzkOVxnwedClGRMRhFOwiIg6jYL+0\n5d4uoJHQefgvnYsqOg9VGu150DV2ERGH0YxdRMRhFOy1YIx53BhjjTGdvV2LNxhjFhpjiowxnxhj\n3jHGdPB2TQ3JGBNvjDlgjDlsjPmlt+vxFmNMd2PMNmPMfmPMPmPML7xdkzcZY3yMMbuNMe95u5Yf\nU7DXwBjTHbgNOOLtWrwoHQix1oYCB4GnvFxPgzHG+ABLgNuBvkCSMaavd6vymgrgcWttX+BWYHoz\nPhcAvwA+9XYR1VGw1+w54Emg2f4YYa1Ns9ZWnHu5E+jmzXoaWH/gsLX2c2vt/wFvAaO9XJNXWGu/\nttbmn/v341SF2g3erco7jDHdgFHAy96upToK9sswxowGvrLWFnq7lkYkGfjA20U0oBuAf/zg9T9p\npmH2Q8aYQCAC+Lt3K/Ga56ma8FV6u5Dq+Hq7AG8zxmQA11Xz0dPAr6i6DON4lzsP1tq/nmvzNFV/\njr/ekLVJ42KMaQesBx6z1n7n7XoamjEmAfjGWptnjBni7Xqq0+yD3Vr7k+reN8a4gCCg0BgDVZcf\n8o0x/a21/2rAEhvEpc7DecaYyUACMNw2rzWyXwHdf/C627n3miVjTEuqQv11a+1fvF2Pl8QCdxlj\n7gD8gGuMMauttRO9XJeb1rHXkjGmGIi21ja7zY+MMfHAYmCwtbbE2/U0JGOML1U/GA+nKtBzgP+x\n1u7zamFeYKpmOCuB/2etfczb9TQG52bsT1hrE7xdyw/pGrvUxp+A9kC6MabAGPOitwtqKOd+NH4Y\n+JCqHwvfbo6hfk4s8DNg2Ln/DgrOzVqlkdGMXUTEYTRjFxFxGAW7iIjDKNhFRBxGwS4i4jAKdhER\nh1Gwi4g4jIJdRMRhFOwiIg7z/wF+5D8E9nguegAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gi5eRnIFpVZu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}