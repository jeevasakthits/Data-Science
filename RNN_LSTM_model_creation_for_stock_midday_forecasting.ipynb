{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN_LSTM_model_creation_for_stock_midday_forecasting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wvgui1rWr7UV",
        "colab_type": "text"
      },
      "source": [
        "**Every Day Stock Market Mid Price Forecasting model creation Deep RNN(LSTM) ***\n",
        "\n",
        "\n",
        "S&P_BSE_FMCG this company data I'm used to foreccast.\n",
        "and using that I'm predicted stock market midprice.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oHU-O15tCuK",
        "colab_type": "text"
      },
      "source": [
        "Importing required Packages for model creaton\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyCaFvFC0tlL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Dropout\n",
        "from sklearn.preprocessing import MinMaxScaler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa-9b68zt1XN",
        "colab_type": "text"
      },
      "source": [
        "Data Reading and splitting that onto training and testing \n",
        "for forecasting \n",
        "<br>\n",
        "Used S&P_BSE_FMCG company stock data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ebUSHz716IQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kl4qYL5WuHOb",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Scaling the Training data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xjsX03kn2E1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "ing_set_scaled = sc.fit_transform(training_set)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BksjrSQuZy2",
        "colab_type": "text"
      },
      "source": [
        "Creating X_train dataset and Y_train dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GkrdFv1m29RN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81Sv565EuiSO",
        "colab_type": "text"
      },
      "source": [
        "Reshapping the training dataset for model creation\n",
        "<br>\n",
        "we can't create model with the single dimentional data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kr8JOjg04zC3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1], 1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1ldMB4muzTi",
        "colab_type": "text"
      },
      "source": [
        "**Model creation**\n",
        "On this step \n",
        "<br>\n",
        "first need to do neural network initialization \n",
        "<br>\n",
        "after initialization need to do add layers for model\n",
        "<br>\n",
        "after to do the model fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpaJFFcV5Y-s",
        "colab_type": "code",
        "outputId": "616db326-6b71-4dc2-adc2-54b1e7cf0f9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "regressor = Sequential()\n",
        "\n",
        "# Adding the first LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True, input_shape = (X_train.shape[1], 1)))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a second LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a third LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50, return_sequences = True))\n",
        "#regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding a fourth LSTM layer and some Dropout regularisation\n",
        "regressor.add(LSTM(units = 50))\n",
        "regressor.add(Dropout(0.2))\n",
        "\n",
        "# Adding the output layer\n",
        "regressor.add(Dense(units = 1))\n",
        "\n",
        "# Compiling the RNN\n",
        "regressor.compile(optimizer = 'adam', loss = 'mean_squared_error')\n",
        "\n",
        "# Fitting the RNN to the Training set\n",
        "regressor.fit(X_train, y_train, epochs = 100, batch_size = 32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "1800/1800 [==============================] - 32s 18ms/step - loss: nan\n",
            "Epoch 2/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 3/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 4/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 5/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 6/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 7/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 8/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 9/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 10/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 11/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 12/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 13/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 14/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 15/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 16/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 17/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 18/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 19/100\n",
            "1800/1800 [==============================] - 29s 16ms/step - loss: nan\n",
            "Epoch 20/100\n",
            "1056/1800 [================>.............] - ETA: 11s - loss: nan"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9bjY5_Hvkku",
        "colab_type": "text"
      },
      "source": [
        "**Model Storing in file**\n",
        "final stage of this project is to store our model into some file \n",
        "the reason for doing this is accessing our model in any time without retraining\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dm0co8W6Knq",
        "colab_type": "code",
        "outputId": "50a50e8a-1d52-4d46-8183-1a9dae539141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "path= \"./RNN_LSTM_MODEL.pkl\"\n",
        "with open(path, 'wb') as f:\n",
        "        pickle.dump(regressor, f)\n",
        "        print(\"Done Pickiling\")\n",
        "        #print(\"Pickled clf at {}\".format(path))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done Pickiling\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWpI8MPNKe2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}