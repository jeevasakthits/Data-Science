{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Video_Analytics.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsvTdF0U6EsC",
        "colab_type": "code",
        "outputId": "db58832d-45de-49c2-ef42-fa24f089c286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install opencv-python"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (3.4.5.20)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.16.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59foAleCm8lR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from skimage.transform import resize\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVK7V3IYuL43",
        "colab_type": "code",
        "outputId": "c0a1b83d-79f4-4c62-da1e-b310920bd5e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count = 0\n",
        "videoFile = \"Tom and jerry.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"frame%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQ4x9pv6uMTf",
        "colab_type": "code",
        "outputId": "746c98f6-5e23-4b6d-8da3-85b105fbfc0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "count = 0\n",
        "videoFile = \"Tom and Jerry 3.mp4\"\n",
        "cap = cv2.VideoCapture(videoFile)\n",
        "frameRate = cap.get(5) #frame rate\n",
        "x=1\n",
        "while(cap.isOpened()):\n",
        "    frameId = cap.get(1) #current frame number\n",
        "    ret, frame = cap.read()\n",
        "    if (ret != True):\n",
        "        break\n",
        "    if (frameId % math.floor(frameRate) == 0):\n",
        "        filename =\"test%d.jpg\" % count;count+=1\n",
        "        cv2.imwrite(filename, frame)\n",
        "cap.release()\n",
        "print (\"Done!\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJY_mzcvuUWB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('mapping.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGtw4qPK7vER",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR_hN4U5uPQX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "for img_name in data.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    X.append(img)\n",
        "X = np.array(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EeeLqbI7uSUf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_image = []\n",
        "for img_name in test.Image_ID:\n",
        "    img = plt.imread('' + img_name)\n",
        "    test_image.append(img)\n",
        "test_img = np.array(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZj0F5DAGVea",
        "colab_type": "code",
        "outputId": "0bae582c-c764-4f91-942b-39a717a514ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Image_ID', 'Class'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyORVTgAF7do",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#trn=list(data[ 'Class'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D20VWex2WA0k",
        "colab_type": "code",
        "outputId": "e85adf9d-4617-4460-c65f-7e158f03664d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Image_ID'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKE0JsEIdr3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils\n",
        "train_y = np_utils.to_categorical(data[\"Class\"])\n",
        "#test_y = np_utils.to_categorical(test[\"Class\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANI2_aKOdtzT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image = []\n",
        "for i in range(0,X.shape[0]):\n",
        "    a = resize(X[i], preserve_range=True, output_shape=(224,224,3)).astype(int)\n",
        "    image.append(a)\n",
        "X = np.array(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAAs5Gn4d1-b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_image = []\n",
        "for i in range(0,test_img.shape[0]):\n",
        "    a = resize(test_img[i], preserve_range=True, output_shape=(224,224)).astype(int)\n",
        "    test_image.append(a)\n",
        "test_image = np.array(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i5h-5rdEHo8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.applications.vgg16 import preprocess_input\n",
        "X = preprocess_input(X, mode='tf')\n",
        "test_image = preprocess_input(test_image, mode='tf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFLD-19oMTh-",
        "colab_type": "code",
        "outputId": "1859111e-bb3d-41bc-bea3-7219dabf7def",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "test_image"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.        , 0.        , 0.        , ..., 0.        , 0.03891182,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.03908537,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.03262569,\n",
              "        0.        ],\n",
              "       ...,\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.04824393,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.04879117,\n",
              "        0.        ],\n",
              "       [0.        , 0.        , 0.        , ..., 0.        , 0.04859591,\n",
              "        0.        ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PaGAzpxMWNN",
        "colab_type": "code",
        "outputId": "954de1dd-7639-4dcc-c301-5931092d4b8e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[ 0.02745104,  0.37254906, -0.01176471],\n",
              "         [ 0.13725495,  0.48235297,  0.082353  ],\n",
              "         [ 0.13725495,  0.48235297,  0.09019613],\n",
              "         ...,\n",
              "         [ 0.14509809,  0.5058824 ,  0.12941182],\n",
              "         [ 0.1686275 ,  0.49803925,  0.12941182],\n",
              "         [ 0.09019613,  0.36470592,  0.02745104]],\n",
              "\n",
              "        [[ 0.02745104,  0.37254906, -0.01176471],\n",
              "         [ 0.13725495,  0.48235297,  0.082353  ],\n",
              "         [ 0.13725495,  0.48235297,  0.09019613],\n",
              "         ...,\n",
              "         [ 0.14509809,  0.5058824 ,  0.12941182],\n",
              "         [ 0.16078436,  0.49803925,  0.12941182],\n",
              "         [ 0.082353  ,  0.36470592,  0.02745104]],\n",
              "\n",
              "        [[ 0.02745104,  0.37254906, -0.01176471],\n",
              "         [ 0.13725495,  0.48235297,  0.082353  ],\n",
              "         [ 0.12941182,  0.48235297,  0.082353  ],\n",
              "         ...,\n",
              "         [ 0.14509809,  0.5137255 ,  0.12941182],\n",
              "         [ 0.16078436,  0.49803925,  0.12941182],\n",
              "         [ 0.07450986,  0.37254906,  0.02745104]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.3490196 , -0.3333333 , -0.32549018],\n",
              "         [-0.27843136, -0.1607843 , -0.32549018],\n",
              "         [-0.38039213, -0.00392157, -0.38039213],\n",
              "         ...,\n",
              "         [-0.70980394, -0.4588235 , -0.47450978],\n",
              "         [-0.7176471 , -0.4588235 , -0.4823529 ],\n",
              "         [-0.7254902 , -0.52156866, -0.5372549 ]],\n",
              "\n",
              "        [[-0.3490196 , -0.3333333 , -0.32549018],\n",
              "         [-0.27843136, -0.1607843 , -0.32549018],\n",
              "         [-0.38039213,  0.00392163, -0.372549  ],\n",
              "         ...,\n",
              "         [-0.70980394, -0.4588235 , -0.47450978],\n",
              "         [-0.7176471 , -0.4588235 , -0.4823529 ],\n",
              "         [-0.7254902 , -0.52156866, -0.5372549 ]],\n",
              "\n",
              "        [[-0.3490196 , -0.3333333 , -0.32549018],\n",
              "         [-0.27843136, -0.1607843 , -0.32549018],\n",
              "         [-0.36470586,  0.0196079 , -0.36470586],\n",
              "         ...,\n",
              "         [-0.70980394, -0.4588235 , -0.47450978],\n",
              "         [-0.7176471 , -0.4588235 , -0.4823529 ],\n",
              "         [-0.7254902 , -0.52156866, -0.5372549 ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.02745104,  0.37254906, -0.01176471],\n",
              "         [ 0.13725495,  0.48235297,  0.09019613],\n",
              "         [ 0.14509809,  0.4901961 ,  0.09803927],\n",
              "         ...,\n",
              "         [ 0.15294123,  0.5137255 ,  0.12156868],\n",
              "         [ 0.16078436,  0.49803925,  0.12156868],\n",
              "         [ 0.082353  ,  0.36470592,  0.02745104]],\n",
              "\n",
              "        [[ 0.02745104,  0.37254906, -0.01176471],\n",
              "         [ 0.13725495,  0.48235297,  0.09019613],\n",
              "         [ 0.14509809,  0.4901961 ,  0.09803927],\n",
              "         ...,\n",
              "         [ 0.14509809,  0.5137255 ,  0.12156868],\n",
              "         [ 0.1686275 ,  0.49803925,  0.12156868],\n",
              "         [ 0.082353  ,  0.36470592,  0.02745104]],\n",
              "\n",
              "        [[ 0.02745104,  0.37254906, -0.01176471],\n",
              "         [ 0.13725495,  0.48235297,  0.09019613],\n",
              "         [ 0.14509809,  0.4901961 ,  0.09803927],\n",
              "         ...,\n",
              "         [ 0.13725495,  0.5137255 ,  0.12156868],\n",
              "         [ 0.15294123,  0.5058824 ,  0.12156868],\n",
              "         [ 0.07450986,  0.37254906,  0.02745104]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.32549018, -0.3333333 , -0.3490196 ],\n",
              "         [-0.23921567, -0.25490195, -0.27058822],\n",
              "         [-0.2235294 , -0.23921567, -0.27843136],\n",
              "         ...,\n",
              "         [-0.62352943, -0.19999999, -0.5294118 ],\n",
              "         [-0.7411765 , -0.3960784 , -0.58431375],\n",
              "         [-0.7490196 , -0.5294118 , -0.58431375]],\n",
              "\n",
              "        [[-0.32549018, -0.3333333 , -0.3490196 ],\n",
              "         [-0.23921567, -0.25490195, -0.27058822],\n",
              "         [-0.21568626, -0.24705881, -0.27843136],\n",
              "         ...,\n",
              "         [-0.7882353 , -0.3960784 , -0.60784316],\n",
              "         [-0.7647059 , -0.45098037, -0.52156866],\n",
              "         [-0.75686276, -0.5529412 , -0.4980392 ]],\n",
              "\n",
              "        [[-0.32549018, -0.3333333 , -0.35686272],\n",
              "         [-0.23921567, -0.25490195, -0.27058822],\n",
              "         [-0.21568626, -0.24705881, -0.27058822],\n",
              "         ...,\n",
              "         [-0.8039216 , -0.4352941 , -0.54509807],\n",
              "         [-0.7647059 , -0.46666664, -0.45098037],\n",
              "         [-0.7647059 , -0.56078434, -0.41960782]]],\n",
              "\n",
              "\n",
              "       [[[-0.08235294,  0.12156868,  0.02745104],\n",
              "         [-0.03529412,  0.27058828,  0.12941182],\n",
              "         [-0.03529412,  0.27058828,  0.13725495],\n",
              "         ...,\n",
              "         [ 0.5372549 ,  0.7019608 ,  0.6862745 ],\n",
              "         [ 0.5372549 ,  0.70980394,  0.6862745 ],\n",
              "         [ 0.34901965,  0.52156866,  0.49803925]],\n",
              "\n",
              "        [[-0.0745098 ,  0.12156868,  0.0196079 ],\n",
              "         [-0.03529412,  0.27058828,  0.12941182],\n",
              "         [-0.04313725,  0.27058828,  0.13725495],\n",
              "         ...,\n",
              "         [ 0.5372549 ,  0.69411767,  0.6862745 ],\n",
              "         [ 0.5372549 ,  0.7019608 ,  0.6862745 ],\n",
              "         [ 0.34901965,  0.5137255 ,  0.49803925]],\n",
              "\n",
              "        [[-0.0745098 ,  0.09803927,  0.07450986],\n",
              "         [-0.03529412,  0.2313726 ,  0.18431377],\n",
              "         [-0.05098039,  0.23921573,  0.1686275 ],\n",
              "         ...,\n",
              "         [ 0.5372549 ,  0.69411767,  0.6862745 ],\n",
              "         [ 0.5372549 ,  0.69411767,  0.6862745 ],\n",
              "         [ 0.34901965,  0.5137255 ,  0.49803925]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.3803922 ,  0.38823533,  0.3411765 ],\n",
              "         [ 0.5686275 ,  0.5764706 ,  0.52156866],\n",
              "         [ 0.5686275 ,  0.5764706 ,  0.5137255 ],\n",
              "         ...,\n",
              "         [ 0.5137255 ,  0.49803925,  0.4666667 ],\n",
              "         [ 0.5058824 ,  0.49803925,  0.4666667 ],\n",
              "         [ 0.33333337,  0.32549024,  0.2941177 ]],\n",
              "\n",
              "        [[ 0.38823533,  0.39607847,  0.34901965],\n",
              "         [ 0.5764706 ,  0.58431375,  0.52156866],\n",
              "         [ 0.5764706 ,  0.58431375,  0.52156866],\n",
              "         ...,\n",
              "         [ 0.52156866,  0.5058824 ,  0.47450984],\n",
              "         [ 0.5137255 ,  0.5058824 ,  0.47450984],\n",
              "         [ 0.33333337,  0.32549024,  0.2941177 ]],\n",
              "\n",
              "        [[ 0.38823533,  0.39607847,  0.34901965],\n",
              "         [ 0.5764706 ,  0.58431375,  0.5294118 ],\n",
              "         [ 0.5764706 ,  0.58431375,  0.52156866],\n",
              "         ...,\n",
              "         [ 0.52156866,  0.5137255 ,  0.48235297],\n",
              "         [ 0.5137255 ,  0.5058824 ,  0.47450984],\n",
              "         [ 0.3411765 ,  0.33333337,  0.2941177 ]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.9529412 ,  0.10588241, -0.6862745 ],\n",
              "         [ 0.78039217,  0.10588241, -0.27843136],\n",
              "         [ 0.45882356,  0.12156868,  0.4039216 ]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.96862745,  0.09803927, -0.6784314 ],\n",
              "         [ 0.92941177,  0.10588241, -0.5686275 ],\n",
              "         [ 0.6784314 ,  0.09019613,  0.03529418]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.9764706 ,  0.09803927, -0.67058825],\n",
              "         [ 0.9764706 ,  0.09803927, -0.6862745 ],\n",
              "         [ 0.9529412 ,  0.09019613, -0.6627451 ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.9529412 ,  0.10588241, -0.6862745 ],\n",
              "         [ 0.78039217,  0.10588241, -0.27843136],\n",
              "         [ 0.45882356,  0.12156868,  0.4039216 ]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.96862745,  0.09803927, -0.6784314 ],\n",
              "         [ 0.92941177,  0.10588241, -0.5686275 ],\n",
              "         [ 0.6784314 ,  0.09019613,  0.03529418]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.9764706 ,  0.09803927, -0.67058825],\n",
              "         [ 0.9764706 ,  0.09803927, -0.6862745 ],\n",
              "         [ 0.9529412 ,  0.09019613, -0.6627451 ]]],\n",
              "\n",
              "\n",
              "       [[[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.9529412 ,  0.10588241, -0.6862745 ],\n",
              "         [ 0.78039217,  0.10588241, -0.27843136],\n",
              "         [ 0.45882356,  0.12156868,  0.4039216 ]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.96862745,  0.09803927, -0.6784314 ],\n",
              "         [ 0.92941177,  0.10588241, -0.5686275 ],\n",
              "         [ 0.6784314 ,  0.09019613,  0.03529418]],\n",
              "\n",
              "        [[ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         [ 0.99215686,  0.11372554, -0.67058825],\n",
              "         ...,\n",
              "         [ 0.9764706 ,  0.09803927, -0.67058825],\n",
              "         [ 0.9764706 ,  0.09803927, -0.6862745 ],\n",
              "         [ 0.9529412 ,  0.09019613, -0.6627451 ]]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_3HzYLIFQba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, train_y, test_size=0.3, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWn1KlSu6xkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.layers import Dense, InputLayer, Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKJFbJIT6xiM",
        "colab_type": "code",
        "outputId": "d70fd6c1-7bbc-4063-cb7c-e85fa38ddcde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        }
      },
      "source": [
        "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0709 09:43:28.045986 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0709 09:43:28.100900 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0709 09:43:28.110384 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0709 09:43:28.171323 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0709 09:43:29.248915 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "W0709 09:43:29.250121 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBqDS1ij6xf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = base_model.predict(X_train)\n",
        "X_valid = base_model.predict(X_valid)\n",
        "test_image = base_model.predict(test_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeciPrrg6xdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(208, 7*7*512)\n",
        "X_valid = X_valid.reshape(90, 7*7*512)\n",
        "test_image = test_image.reshape(186, 7*7*512)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yD7-j_Pl6xbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = X_train/X_train.max()\n",
        "X_valid = X_valid/X_train.max()\n",
        "test_image = test_image/test_image.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiMDxbks6xZE",
        "colab_type": "code",
        "outputId": "a2586fd2-84e8-4f32-e9da-cb71238054a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "model = Sequential()\n",
        "model.add(InputLayer((7*7*512,)))    # input layer\n",
        "model.add(Dense(units=1024, activation='sigmoid'))   # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=512, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(units=256, activation='sigmoid'))    # hidden layer\n",
        "model.add(Dropout(0.5))      # adding dropout\n",
        "model.add(Dense(3, activation='softmax'))            # output layer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0709 09:51:07.209650 139663183693696 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0709 09:51:07.306525 139663183693696 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWmxWKZZ6xWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
        "class_weights = compute_class_weight('balanced',np.unique(data.Class), data.Class)  # computing weights of different classes\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i6dHCUYE6xUc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath=\"weights.best.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]      # model check pointing based on validation loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Kd8rEhZ6xSA",
        "colab_type": "code",
        "outputId": "c1ddcb20-727f-49b1-9298-7b6e2e4d0b08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(train, y_train, epochs=100, validation_data=(X_valid, y_valid), class_weight=class_weights, callbacks=callbacks_list)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 208 samples, validate on 90 samples\n",
            "Epoch 1/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0458 - acc: 0.9856 - val_loss: 0.3939 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 0.39393, saving model to weights.best.hdf5\n",
            "Epoch 2/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0251 - acc: 0.9904 - val_loss: 0.3845 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00002: val_loss improved from 0.39393 to 0.38449, saving model to weights.best.hdf5\n",
            "Epoch 3/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0699 - acc: 0.9712 - val_loss: 0.5784 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 0.38449\n",
            "Epoch 4/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0468 - acc: 0.9856 - val_loss: 0.3542 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.38449 to 0.35420, saving model to weights.best.hdf5\n",
            "Epoch 5/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0503 - acc: 0.9856 - val_loss: 0.5352 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 0.35420\n",
            "Epoch 6/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0381 - acc: 0.9904 - val_loss: 0.4182 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 0.35420\n",
            "Epoch 7/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0242 - acc: 0.9952 - val_loss: 0.4579 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 0.35420\n",
            "Epoch 8/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0375 - acc: 0.9952 - val_loss: 0.5607 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 0.35420\n",
            "Epoch 9/100\n",
            "208/208 [==============================] - 3s 14ms/step - loss: 0.0149 - acc: 0.9952 - val_loss: 0.3736 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 0.35420\n",
            "Epoch 10/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0250 - acc: 0.9904 - val_loss: 0.4015 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.35420\n",
            "Epoch 11/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0321 - acc: 0.9904 - val_loss: 0.4594 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 0.35420\n",
            "Epoch 12/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 0.35420\n",
            "Epoch 13/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0243 - acc: 0.9904 - val_loss: 0.4603 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 0.35420\n",
            "Epoch 14/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0371 - acc: 0.9904 - val_loss: 0.4140 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 0.35420\n",
            "Epoch 15/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.3957 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 0.35420\n",
            "Epoch 16/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0155 - acc: 0.9904 - val_loss: 0.4106 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 0.35420\n",
            "Epoch 17/100\n",
            "208/208 [==============================] - 3s 16ms/step - loss: 0.0128 - acc: 0.9952 - val_loss: 0.4274 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 0.35420\n",
            "Epoch 18/100\n",
            "208/208 [==============================] - 3s 16ms/step - loss: 0.0177 - acc: 0.9904 - val_loss: 0.4491 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 0.35420\n",
            "Epoch 19/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0246 - acc: 0.9904 - val_loss: 0.4831 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 0.35420\n",
            "Epoch 20/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0121 - acc: 0.9904 - val_loss: 0.4653 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 0.35420\n",
            "Epoch 21/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.5124 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 0.35420\n",
            "Epoch 22/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0070 - acc: 1.0000 - val_loss: 0.4347 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 0.35420\n",
            "Epoch 23/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0190 - acc: 0.9952 - val_loss: 0.3935 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 0.35420\n",
            "Epoch 24/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0164 - acc: 0.9952 - val_loss: 0.4078 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 0.35420\n",
            "Epoch 25/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0105 - acc: 0.9952 - val_loss: 0.4952 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 0.35420\n",
            "Epoch 26/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 0.5326 - val_acc: 0.8333\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 0.35420\n",
            "Epoch 27/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0229 - acc: 0.9904 - val_loss: 0.4326 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 0.35420\n",
            "Epoch 28/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0258 - acc: 0.9904 - val_loss: 0.3884 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 0.35420\n",
            "Epoch 29/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0077 - acc: 1.0000 - val_loss: 0.3931 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 0.35420\n",
            "Epoch 30/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0211 - acc: 0.9952 - val_loss: 0.4441 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 0.35420\n",
            "Epoch 31/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0167 - acc: 0.9952 - val_loss: 0.4726 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 0.35420\n",
            "Epoch 32/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0119 - acc: 0.9952 - val_loss: 0.4920 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 0.35420\n",
            "Epoch 33/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0069 - acc: 0.9952 - val_loss: 0.4012 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 0.35420\n",
            "Epoch 34/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0116 - acc: 0.9952 - val_loss: 0.3996 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00034: val_loss did not improve from 0.35420\n",
            "Epoch 35/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0093 - acc: 0.9952 - val_loss: 0.4448 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00035: val_loss did not improve from 0.35420\n",
            "Epoch 36/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5103 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00036: val_loss did not improve from 0.35420\n",
            "Epoch 37/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0130 - acc: 0.9952 - val_loss: 0.5389 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00037: val_loss did not improve from 0.35420\n",
            "Epoch 38/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0147 - acc: 0.9904 - val_loss: 0.4905 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00038: val_loss did not improve from 0.35420\n",
            "Epoch 39/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0116 - acc: 0.9952 - val_loss: 0.5264 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00039: val_loss did not improve from 0.35420\n",
            "Epoch 40/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0120 - acc: 0.9904 - val_loss: 0.4896 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00040: val_loss did not improve from 0.35420\n",
            "Epoch 41/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0184 - acc: 0.9904 - val_loss: 0.4374 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00041: val_loss did not improve from 0.35420\n",
            "Epoch 42/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0063 - acc: 1.0000 - val_loss: 0.4136 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00042: val_loss did not improve from 0.35420\n",
            "Epoch 43/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0033 - acc: 1.0000 - val_loss: 0.4156 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00043: val_loss did not improve from 0.35420\n",
            "Epoch 44/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0109 - acc: 0.9952 - val_loss: 0.4443 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00044: val_loss did not improve from 0.35420\n",
            "Epoch 45/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5319 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00045: val_loss did not improve from 0.35420\n",
            "Epoch 46/100\n",
            "208/208 [==============================] - 3s 14ms/step - loss: 0.0148 - acc: 0.9904 - val_loss: 0.6021 - val_acc: 0.8444\n",
            "\n",
            "Epoch 00046: val_loss did not improve from 0.35420\n",
            "Epoch 47/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0165 - acc: 0.9904 - val_loss: 0.5331 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00047: val_loss did not improve from 0.35420\n",
            "Epoch 48/100\n",
            "208/208 [==============================] - 3s 14ms/step - loss: 0.0058 - acc: 0.9952 - val_loss: 0.5197 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00048: val_loss did not improve from 0.35420\n",
            "Epoch 49/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4945 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00049: val_loss did not improve from 0.35420\n",
            "Epoch 50/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0271 - acc: 0.9904 - val_loss: 0.4949 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00050: val_loss did not improve from 0.35420\n",
            "Epoch 51/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0135 - acc: 0.9952 - val_loss: 0.5168 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00051: val_loss did not improve from 0.35420\n",
            "Epoch 52/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0099 - acc: 0.9952 - val_loss: 0.4786 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00052: val_loss did not improve from 0.35420\n",
            "Epoch 53/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0069 - acc: 0.9952 - val_loss: 0.4349 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00053: val_loss did not improve from 0.35420\n",
            "Epoch 54/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0143 - acc: 0.9904 - val_loss: 0.4117 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00054: val_loss did not improve from 0.35420\n",
            "Epoch 55/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0168 - acc: 0.9904 - val_loss: 0.4110 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00055: val_loss did not improve from 0.35420\n",
            "Epoch 56/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0043 - acc: 1.0000 - val_loss: 0.4206 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00056: val_loss did not improve from 0.35420\n",
            "Epoch 57/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0093 - acc: 0.9952 - val_loss: 0.4407 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00057: val_loss did not improve from 0.35420\n",
            "Epoch 58/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0053 - acc: 1.0000 - val_loss: 0.4634 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00058: val_loss did not improve from 0.35420\n",
            "Epoch 59/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0129 - acc: 0.9904 - val_loss: 0.4848 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00059: val_loss did not improve from 0.35420\n",
            "Epoch 60/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0137 - acc: 0.9952 - val_loss: 0.4420 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00060: val_loss did not improve from 0.35420\n",
            "Epoch 61/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0106 - acc: 0.9952 - val_loss: 0.4418 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00061: val_loss did not improve from 0.35420\n",
            "Epoch 62/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0044 - acc: 1.0000 - val_loss: 0.4443 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00062: val_loss did not improve from 0.35420\n",
            "Epoch 63/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0251 - acc: 0.9904 - val_loss: 0.4719 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00063: val_loss did not improve from 0.35420\n",
            "Epoch 64/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0173 - acc: 0.9952 - val_loss: 0.5028 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00064: val_loss did not improve from 0.35420\n",
            "Epoch 65/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0133 - acc: 0.9952 - val_loss: 0.5362 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00065: val_loss did not improve from 0.35420\n",
            "Epoch 66/100\n",
            "208/208 [==============================] - 3s 14ms/step - loss: 0.0078 - acc: 0.9952 - val_loss: 0.5055 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00066: val_loss did not improve from 0.35420\n",
            "Epoch 67/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0175 - acc: 0.9904 - val_loss: 0.4480 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00067: val_loss did not improve from 0.35420\n",
            "Epoch 68/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0100 - acc: 0.9904 - val_loss: 0.4313 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00068: val_loss did not improve from 0.35420\n",
            "Epoch 69/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0061 - acc: 1.0000 - val_loss: 0.4428 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00069: val_loss did not improve from 0.35420\n",
            "Epoch 70/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0084 - acc: 0.9952 - val_loss: 0.4591 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00070: val_loss did not improve from 0.35420\n",
            "Epoch 71/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.4304 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00071: val_loss did not improve from 0.35420\n",
            "Epoch 72/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0090 - acc: 0.9952 - val_loss: 0.4273 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00072: val_loss did not improve from 0.35420\n",
            "Epoch 73/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0141 - acc: 0.9952 - val_loss: 0.4565 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00073: val_loss did not improve from 0.35420\n",
            "Epoch 74/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.4869 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00074: val_loss did not improve from 0.35420\n",
            "Epoch 75/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0088 - acc: 0.9952 - val_loss: 0.5099 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00075: val_loss did not improve from 0.35420\n",
            "Epoch 76/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0191 - acc: 0.9904 - val_loss: 0.5260 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00076: val_loss did not improve from 0.35420\n",
            "Epoch 77/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0119 - acc: 0.9952 - val_loss: 0.5786 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00077: val_loss did not improve from 0.35420\n",
            "Epoch 78/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0076 - acc: 0.9952 - val_loss: 0.4850 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00078: val_loss did not improve from 0.35420\n",
            "Epoch 79/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0114 - acc: 0.9904 - val_loss: 0.4367 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00079: val_loss did not improve from 0.35420\n",
            "Epoch 80/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0063 - acc: 0.9952 - val_loss: 0.4508 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00080: val_loss did not improve from 0.35420\n",
            "Epoch 81/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0093 - acc: 0.9952 - val_loss: 0.4959 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00081: val_loss did not improve from 0.35420\n",
            "Epoch 82/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.5108 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00082: val_loss did not improve from 0.35420\n",
            "Epoch 83/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0092 - acc: 0.9904 - val_loss: 0.5179 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00083: val_loss did not improve from 0.35420\n",
            "Epoch 84/100\n",
            "208/208 [==============================] - 3s 14ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.5079 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00084: val_loss did not improve from 0.35420\n",
            "Epoch 85/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.4852 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00085: val_loss did not improve from 0.35420\n",
            "Epoch 86/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0092 - acc: 0.9952 - val_loss: 0.4737 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00086: val_loss did not improve from 0.35420\n",
            "Epoch 87/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0060 - acc: 0.9952 - val_loss: 0.4815 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00087: val_loss did not improve from 0.35420\n",
            "Epoch 88/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0129 - acc: 0.9952 - val_loss: 0.4800 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00088: val_loss did not improve from 0.35420\n",
            "Epoch 89/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0140 - acc: 0.9904 - val_loss: 0.4275 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00089: val_loss did not improve from 0.35420\n",
            "Epoch 90/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0144 - acc: 0.9952 - val_loss: 0.4281 - val_acc: 0.9000\n",
            "\n",
            "Epoch 00090: val_loss did not improve from 0.35420\n",
            "Epoch 91/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 0.4892 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00091: val_loss did not improve from 0.35420\n",
            "Epoch 92/100\n",
            "208/208 [==============================] - 3s 14ms/step - loss: 0.0327 - acc: 0.9904 - val_loss: 0.5394 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00092: val_loss did not improve from 0.35420\n",
            "Epoch 93/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0127 - acc: 0.9904 - val_loss: 0.5209 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00093: val_loss did not improve from 0.35420\n",
            "Epoch 94/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0115 - acc: 0.9952 - val_loss: 0.5462 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00094: val_loss did not improve from 0.35420\n",
            "Epoch 95/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0112 - acc: 0.9952 - val_loss: 0.5347 - val_acc: 0.8556\n",
            "\n",
            "Epoch 00095: val_loss did not improve from 0.35420\n",
            "Epoch 96/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0107 - acc: 0.9952 - val_loss: 0.4924 - val_acc: 0.8667\n",
            "\n",
            "Epoch 00096: val_loss did not improve from 0.35420\n",
            "Epoch 97/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0130 - acc: 0.9952 - val_loss: 0.4575 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00097: val_loss did not improve from 0.35420\n",
            "Epoch 98/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0137 - acc: 0.9952 - val_loss: 0.4555 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00098: val_loss did not improve from 0.35420\n",
            "Epoch 99/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0087 - acc: 0.9952 - val_loss: 0.4713 - val_acc: 0.8889\n",
            "\n",
            "Epoch 00099: val_loss did not improve from 0.35420\n",
            "Epoch 100/100\n",
            "208/208 [==============================] - 3s 15ms/step - loss: 0.0127 - acc: 0.9904 - val_loss: 0.4855 - val_acc: 0.8778\n",
            "\n",
            "Epoch 00100: val_loss did not improve from 0.35420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0586e656d8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY4X27xP6xPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.load_weights(\"weights.best.hdf5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5LZvNR_6xL5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5BLM2CZ6xJJ",
        "colab_type": "code",
        "outputId": "e89f969d-16cf-49ed-c75e-00c32f7f3242",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "source": [
        "scores = model.evaluate(test_image, test_y)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-e0e935242480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s: %.2f%%\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lp05B36Ha3c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}